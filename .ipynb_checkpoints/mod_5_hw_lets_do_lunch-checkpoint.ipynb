{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Homework - Let's Get Lunch\n",
    "\n",
    "Suppose we are looking for a good place for lunch on our next trip to La Crosse. Let's collect some data on nearby restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Problem 1 </font>\n",
    "\n",
    "Goto yelp.com and perform a search with the following parameters\n",
    "\n",
    "* **Find** Restaurants\n",
    "* **Near** La Crosse, WI\n",
    "\n",
    "**Tasks**\n",
    "1. Copy the resulting web address below and determine the how the     specified search terms related to the resulting address\n",
    "2. Use requests and Beautiful Soap to download the content of the front page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: composable in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already up-to-date: composablesoup in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4<5.0.0,>=4.9.3 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied, skipping upgrade: composable<0.3.0,>=0.2.0 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/dcmdillon/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install composable --upgrade\n",
    "!pip install composablesoup --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composable import pipeable\n",
    "from composable.strict import map, filter\n",
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composablesoup.soup import find_parent, parents, children, find_previous_sibling, find_previous_siblings, find_next_sibling, find_next_siblings, find_previous_sibling\n",
    "from composable.sequence import to_list, head\n",
    "from composable.string import strip\n",
    "from composable import from_toolz as tlz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.yelp.com/search?find_desc=Restaurants&find_loc=La%20Crosse%2C%20WI')\n",
    "food = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=\"red\"> Problem 2 </font>\n",
    "\n",
    "We want to grab the restaurant's name.\n",
    "\n",
    "1. Use Inspect Element to determine the tags/classes for each of the elements listed above.  \n",
    "2. Note that all the business information is contained in a`div` that contains a class similar to  `<div class=\" ... businessName__09f24__3Wql2 ...\">`.  You will need to use a regular expression to match the `businessName` in the class (see lecture 5.3).\n",
    "3. Write expressions/functions to pull out the name of each restaurant.  \n",
    "    * Note: The business name is in an unnamed tag, you will need to navigate to the using searches and/or relationship\n",
    " \n",
    "**Confirm that there is an extra restaurant in the list (e.g. 11-12 instead of 10). This is due to an advertisement/sponsered links, which we want to ignore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pappi’s Taqueria y Mas',\n",
       " 'Restore Public House',\n",
       " 'The Waterfront Restaurant & Tavern',\n",
       " 'Lovechild Restaurant',\n",
       " 'The Charmant',\n",
       " 'Buzzard Billy’s',\n",
       " 'Howie’s on La Crosse',\n",
       " 'Greengrass Cafe',\n",
       " 'The Freighthouse Restaurant',\n",
       " 'Schuby’s Neighborhood Butcher',\n",
       " 'The Root Note']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "result = (food\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>map(find('a'))\n",
    " >>map(get_text)\n",
    ")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "remove_ad = pipeable(lambda ls: [li for li in ls if re.match(\"\\d\",get_text(li))])\n",
    "get_name = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >>map(find('a'))\n",
    " >>map(get_text)\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restore Public House',\n",
       " 'The Waterfront Restaurant & Tavern',\n",
       " 'Lovechild Restaurant',\n",
       " 'The Charmant',\n",
       " 'Buzzard Billy’s',\n",
       " 'Howie’s on La Crosse',\n",
       " 'Greengrass Cafe',\n",
       " 'The Freighthouse Restaurant',\n",
       " 'Schuby’s Neighborhood Butcher',\n",
       " 'The Root Note']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Problem 3 </font>\n",
    "\n",
    "Since we picked up extra information, we will need to be clever about identifying the information block for each restaurant.  Note that all of the actual search results (but not sponsered links) start with the ranking (e.g. `11.`).  Use the following steps to get a list that contains the information for each restaurant other than the adds.\n",
    "\n",
    "1. Start by finding the ranking of the restaurant (1., 2., etc.). **Hint:** You will need to use regular expression to match the text of the tag (see lecture 5.3).\n",
    "2. Now search for a parent of the above tags that surrounds all of the restaurant information.  You will want to use the `find_parent` method on each of the tags from **1.**.  **Hint:** Look through each of the `div` tags that contain the ranking, looking for a meaningful tag name to match with a regular expression.\n",
    "\n",
    "The resulting list will be the starting point for gathering all of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperate_rank = pipeable(lambda ls: [li.split(\".\")[0] for li in ls])\n",
    "result = (food\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >>map(find('span'))\n",
    " >>map(get_text)\n",
    " >>seperate_rank\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rank = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >>map(find('span'))\n",
    " >>map(get_text)\n",
    " >>seperate_rank\n",
    ")\n",
    "get_rank(food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Problem 4 </font>\n",
    "\n",
    "Write expressions/functions to gather each of the following pieces of information for each of the restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restaurant Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restore Public House',\n",
       " 'The Waterfront Restaurant & Tavern',\n",
       " 'Lovechild Restaurant',\n",
       " 'The Charmant',\n",
       " 'Buzzard Billy’s',\n",
       " 'Howie’s on La Crosse',\n",
       " 'Greengrass Cafe',\n",
       " 'The Freighthouse Restaurant',\n",
       " 'Schuby’s Neighborhood Butcher',\n",
       " 'The Root Note']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >>map(find('a'))\n",
    " >>map(get_text)\n",
    " \n",
    ")\n",
    "get_name(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.5 star rating',\n",
       " '4.5 star rating',\n",
       " '4.5 star rating',\n",
       " '4.5 star rating',\n",
       " '4 star rating',\n",
       " '4 star rating',\n",
       " '4 star rating',\n",
       " '4 star rating',\n",
       " '4.5 star rating',\n",
       " '4.5 star rating']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rating = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >> map(find_parent)\n",
    " >> map(find_parent)\n",
    " >> map(find('div', attrs={'class': re.compile('i-stars')}))\n",
    " >> filter(has_attr('aria-label'))\n",
    " >> map(tlz.get('aria-label'))\n",
    ")\n",
    "get_rating(food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1810 State St',\n",
       " '328 Front St S',\n",
       " '300 3rd St S',\n",
       " '101 State St',\n",
       " '222 Pearl St',\n",
       " '1128 La Crosse St',\n",
       " '1904 Campbell Rd',\n",
       " '107 Vine St',\n",
       " '321 State St',\n",
       " '115 4th St S']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_address = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >> map(find_parent)\n",
    " >> map(find_parent)\n",
    " >> map(find_parent)\n",
    " >>map(find_next_sibling)\n",
    " >>map(find('address'))\n",
    " >>map(get_text) \n",
    ")\n",
    "get_address(food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '226', '109', '149', '275', '57', '96', '125', '17', '80']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reviewCount = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >> map(find_parent)\n",
    " >> map(find_parent)\n",
    " >> map(find('span', attrs={'class': re.compile('reviewCount')}))\n",
    " >>map(get_text)\n",
    ")\n",
    "\n",
    "get_reviewCount(food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category\n",
    "\n",
    "**Examples:** `['American (New)', 'Seafood', 'Steakhouses']` becomes `'American (New);Seafood;Steakhouses'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_DollarSigns = pipeable(lambda l: l.replace(\"$\",\"\"))\n",
    "replace_Commas = pipeable(lambda l: l.replace(\", \",\";\"))\n",
    "\n",
    "get_GetCategory = pipeable(lambda soup: soup\n",
    " >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    " >>remove_ad\n",
    " >> map(find_parent)\n",
    " >> map(find_parent)\n",
    " >> map(find('div', attrs={'class': re.compile('priceCategory')}))\n",
    " >>map(get_text)\n",
    " >>map(remove_DollarSigns)\n",
    " >>map(replace_Commas)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['American (Traditional)',\n",
       " 'American (New);Seafood;Steakhouses',\n",
       " 'American (New)',\n",
       " 'French;Cocktail Bars',\n",
       " 'American (Traditional);Cajun/Creole',\n",
       " 'American (New);Pubs',\n",
       " 'Breakfast & Brunch;Bars',\n",
       " 'Seafood;Steakhouses;Desserts',\n",
       " 'Butcher;Delis;Caterers',\n",
       " 'Music Venues;Coffee & Tea;Creperies']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_GetCategory(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">  Problem 4 </font>\n",
    "\n",
    "Package all of the expressions in a function that takes a url as input and returns the table of information.  Use a `def` statement and put the above helper functions in the body of the main function.  Test this function on the front page of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Restore Public House',\n",
       "  '1',\n",
       "  '4.5 star rating',\n",
       "  '1810 State St',\n",
       "  '17',\n",
       "  'American (Traditional)'],\n",
       " ['The Waterfront Restaurant & Tavern',\n",
       "  '2',\n",
       "  '4.5 star rating',\n",
       "  '328 Front St S',\n",
       "  '226',\n",
       "  'American (New);Seafood;Steakhouses'],\n",
       " ['Lovechild Restaurant',\n",
       "  '3',\n",
       "  '4.5 star rating',\n",
       "  '300 3rd St S',\n",
       "  '109',\n",
       "  'American (New)'],\n",
       " ['The Charmant',\n",
       "  '4',\n",
       "  '4.5 star rating',\n",
       "  '101 State St',\n",
       "  '149',\n",
       "  'French;Cocktail Bars'],\n",
       " ['Buzzard Billy’s',\n",
       "  '5',\n",
       "  '4 star rating',\n",
       "  '222 Pearl St',\n",
       "  '275',\n",
       "  'American (Traditional);Cajun/Creole'],\n",
       " ['Howie’s on La Crosse',\n",
       "  '6',\n",
       "  '4 star rating',\n",
       "  '1128 La Crosse St',\n",
       "  '57',\n",
       "  'American (New);Pubs'],\n",
       " ['Greengrass Cafe',\n",
       "  '7',\n",
       "  '4 star rating',\n",
       "  '1904 Campbell Rd',\n",
       "  '96',\n",
       "  'Breakfast & Brunch;Bars'],\n",
       " ['The Freighthouse Restaurant',\n",
       "  '8',\n",
       "  '4 star rating',\n",
       "  '107 Vine St',\n",
       "  '125',\n",
       "  'Seafood;Steakhouses;Desserts'],\n",
       " ['Schuby’s Neighborhood Butcher',\n",
       "  '9',\n",
       "  '4.5 star rating',\n",
       "  '321 State St',\n",
       "  '17',\n",
       "  'Butcher;Delis;Caterers'],\n",
       " ['The Root Note',\n",
       "  '10',\n",
       "  '4.5 star rating',\n",
       "  '115 4th St S',\n",
       "  '80',\n",
       "  'Music Venues;Coffee & Tea;Creperies']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yelpScrape(url):\n",
    "    s = requests.Session()\n",
    "    r = s.get(url)\n",
    "    food = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    remove_ad = pipeable(lambda ls: [li for li in ls if re.match(\"\\d\",get_text(li))])\n",
    "    seperate_rank = pipeable(lambda ls: [li.split(\".\")[0] for li in ls])\n",
    "    remove_DollarSigns = pipeable(lambda l: l.replace(\"$\",\"\"))\n",
    "    replace_Commas = pipeable(lambda l: l.replace(\", \",\";\"))\n",
    "    safe_getText = pipeable(lambda l: l.text if l is not None else \"\")\n",
    "    safe_getStars = pipeable(lambda l: l[\"aria-label\"] if l is not None else \"\")\n",
    "    \n",
    "    \n",
    "    get_name = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >>map(find('a'))\n",
    "     >>map(safe_getText)\n",
    "    )\n",
    "    \n",
    "    get_rank = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >>map(find('span'))\n",
    "     >>map(safe_getText)\n",
    "     >>seperate_rank\n",
    "    )\n",
    "    \n",
    "    get_rating = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >> map(find_parent)\n",
    "     >> map(find_parent)\n",
    "     >> map(find('div', attrs={'class': re.compile('i-stars')}))\n",
    "     >> map(safe_getStars)\n",
    "    )\n",
    "    \n",
    "    get_address = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >> map(find_parent)\n",
    "     >> map(find_parent)\n",
    "     >> map(find_parent)\n",
    "     >>map(find_next_sibling)\n",
    "     >>map(find('address'))\n",
    "     >>map(safe_getText) \n",
    "    )\n",
    "    \n",
    "    get_reviewCount = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >> map(find_parent)\n",
    "     >> map(find_parent)\n",
    "     >> map(find('span', attrs={'class': re.compile('reviewCount')}))\n",
    "     >>map(safe_getText)\n",
    "    )\n",
    "\n",
    "    get_GetCategory = pipeable(lambda soup: soup\n",
    "     >> find_all('div', attrs={'class': re.compile('businessName')})\n",
    "     >>remove_ad\n",
    "     >> map(find_parent)\n",
    "     >> map(find_parent)\n",
    "     >> map(find('div', attrs={'class': re.compile('priceCategory')}))\n",
    "     >>map(safe_getText)\n",
    "     >>map(remove_DollarSigns)\n",
    "     >>map(replace_Commas)\n",
    "    )\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    data = [list(a) for a in zip(get_name(food),get_rank(food),get_rating(food),get_address(food),get_reviewCount(food),get_GetCategory(food))]\n",
    "    return data\n",
    "\n",
    "\n",
    "yelpScrape(\"https://www.yelp.com/search?find_desc=Restaurants&find_loc=La%20Crosse%2C%20WI&&start=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">  Problem 5 </font>\n",
    "\n",
    "Now perform a linear search to grab all of the information on restaurants in La Crosse.  You will need to\n",
    "\n",
    "1. Inspect the url for the first, second, etc. pages to determine the pattern.\n",
    "2. Create a list of urls for all search results.\n",
    "3. Get the info from all pages and use your function from the last problem to parse the data into a list.\n",
    "4. Write the results to a csv file. **Hint:** Use `'a'` (append) instead of `'w'` write on all after the first/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in range(0,24):\n",
    "    \n",
    "    urls.append(\"https://www.yelp.com/search?find_desc=Restaurants&find_loc=La%20Crosse%2C%20WI&&start=\" + str(i *10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yelp_data.csv','a') as outfile:\n",
    "    for url in urls:\n",
    "\n",
    "        data = yelpScrape(url)\n",
    "        data = [\",\".join(a) for a in data]\n",
    "        data = \"\\n\".join(data)\n",
    "        outfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">  Bonus Problem </font>\n",
    "\n",
    "See if you can also grab the latitude and longitude of each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
